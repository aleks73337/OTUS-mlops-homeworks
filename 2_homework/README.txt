1. Создать новый backet в Yandex Cloud Object Storage и скопировать
в него содержимое предоставленного Вам хранилища с использованием инструмента s3cmd. Для проверки преподавателем данный basket необходимо
сделать общедоступным, а точку доступа к нему привести в README-файле
Вашего GitHub-репозитория.

Result:
s3://mlops-asomov/fraud-data/

2. Создать Spark-кластер в Data Proc с двумя подкластерами со следующими характеристиками:
а) Мастер-подкластер: класс хоста s3-c2-m8, размер хранилища 40 ГБ.
б) Data-подкластер: класс хоста s3-c4-m16, 3 хоста, размер хранилища
128 ГБ.

3. Соединиться по SSH с мастер-узлом и выполнить на нём команду копирования содержимого хранилища в файловую систему HDFS с использованием инструмента hadoop distcp. Для проверки преподавателем необходимо
вывести содержимое HDFS-директории в консоль, а снимок экрана с этой информацией привести в README-файле Вашего GitHub-репозитория.
